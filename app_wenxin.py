import sys
import sqlite3
# å¼ºåˆ¶ä¿®æ”¹ç‰ˆæœ¬å·ï¼ˆä»…å¼€å‘ç¯å¢ƒä½¿ç”¨ï¼‰
if sqlite3.sqlite_version_info < (3, 35, 0):
    sqlite3.sqlite_version = "3.38.0"  # ä¼ªè£…ç‰ˆæœ¬å·
    sqlite3.sqlite_version_info = (3, 38, 0)

# ç¡®ä¿chromadbä½¿ç”¨ä¿®æ”¹åçš„ç‰ˆæœ¬
sys.modules["sqlite3"] = sqlite3
import streamlit as st
from fact_checker_v4_wenxin import FactChecker
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIè™šå‡æ–°é—»æ£€æµ‹å™¨",
    page_icon="ğŸ”",
    layout="wide",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': None
    }
)

# åº”ç”¨æ ‡é¢˜å’Œæè¿°
st.title("AIè™šå‡æ–°é—»æ£€æµ‹å™¨")
st.markdown("""
æœ¬åº”ç”¨ç¨‹åºä½¿ç”¨æ–‡å¿ƒå¤§æ¨¡å‹APIéªŒè¯æ–°é—»é™ˆè¿°çš„å‡†ç¡®æ€§ã€‚
è¯·åœ¨ä¸‹æ–¹è¾“å…¥éœ€è¦æ ¸æŸ¥çš„æ–°é—»ï¼Œç³»ç»Ÿå°†æ£€ç´¢ç½‘ç»œè¯æ®è¿›è¡Œæ–°é—»æ ¸æŸ¥ï¼Œæ— ç½‘ç»œæ—¶å°†åªè¿›è¡Œæœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ã€‚
""")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("é…ç½®")
    # æ¨¡å‹é€‰æ‹© - æ¨èç”¨æ–‡å¿ƒæ”¯æŒçš„æ¨¡å‹
    model_option = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        [
            "ernie-3.5-8k",
            "ernie-4.0-turbo-8k",
            "ernie-4.5-turbo-128k-preview"
        ],
        index=0,
        help="é€‰æ‹©æ–‡å¿ƒå¤§æ¨¡å‹"
    )
    with st.expander("é«˜çº§è®¾ç½®"):
        temperature = st.slider("æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.0, step=0.1,
                               help="è¾ƒä½çš„å€¼ä½¿å“åº”æ›´ç¡®å®šï¼Œè¾ƒé«˜çš„å€¼ä½¿å“åº”æ›´å…·åˆ›é€ æ€§")
        max_tokens = st.slider("æœ€å¤§å“åº”é•¿åº¦", min_value=100, max_value=8000, value=1000, step=100,
                              help="å“åº”ä¸­çš„æœ€å¤§æ ‡è®°æ•°")
    st.divider()
    st.markdown("### å…³äº ###")
    st.markdown("è™šå‡æ–°é—»æ£€æµ‹å™¨:")
    st.markdown("1. ä»æ–°é—»ä¸­æå–æ ¸å¿ƒå£°æ˜")
    st.markdown("2. åœ¨ç½‘ç»œä¸Šå’Œæœ¬åœ°åº“æœç´¢è¯æ®")
    st.markdown("3. ä½¿ç”¨BGE-M3æŒ‰ç›¸å…³æ€§å¯¹è¯æ®è¿›è¡Œæ’å")
    st.markdown("4. åŸºäºè¯æ®æä¾›ç»“è®º")
    st.markdown("ä½¿ç”¨LLMã€Streamlitã€BGE-M3å’ŒRAGå¼€å‘ â¤ï¸â¤ï¸â¤ï¸")

if 'messages' not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

user_input = st.chat_input("è¯·åœ¨ä¸‹æ–¹è¾“å…¥éœ€è¦æ ¸æŸ¥çš„æ–°é—»...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    assistant_message = st.chat_message("assistant")
    claim_placeholder = assistant_message.empty()
    information_placeholder = assistant_message.empty()
    evidence_placeholder = assistant_message.empty()
    verdict_placeholder = assistant_message.empty()

    # åˆå§‹åŒ–FactChecker
    fact_checker = FactChecker(
        api_base="https://aistudio.baidu.com/llm/lmapi/v3",
        model=model_option,
        temperature=temperature,
        max_tokens=max_tokens
    )

    # ç¬¬1æ­¥ï¼šæå–å£°æ˜
    claim_placeholder.markdown("### ğŸ” æ­£åœ¨æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜...")
    claim = fact_checker.extract_claim(user_input)
    if "claim:" in claim.lower():
        claim = claim.split("claim:")[-1].strip()
    claim_placeholder.markdown(f"### ğŸ” æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜\n\n{claim}")

    # ç¬¬2æ­¥ï¼šæå–å…³é”®ä¿¡æ¯
    information_placeholder.markdown(f"### ğŸ” æ­£åœ¨æå–æ–°é—»çš„å…³é”®ä¿¡æ¯...")
    information = fact_checker.extract_keyinformation(user_input)
    information_placeholder.markdown(f"### ğŸ” æå–æ–°é—»çš„å…³é”®ä¿¡æ¯\n\n{information}")

    # ç¬¬3æ­¥ï¼šæœç´¢è¯æ®
    evidence_placeholder.markdown("### ğŸŒ æ­£åœ¨æœç´¢ç›¸å…³è¯æ®...")
    evidence_docs = fact_checker.search_evidence(claim)

    # ç¬¬4æ­¥ï¼šè·å–ç›¸å…³è¯æ®å—
    evidence_placeholder.markdown("### ğŸŒ æ­£åœ¨åˆ†æè¯æ®ç›¸å…³æ€§...")
    evidence_chunks = fact_checker.get_evidence_chunks(evidence_docs, claim)

    # æ˜¾ç¤ºè¯æ®ç»“æœ
    evidence_md = "### ğŸ”— è¯æ®æ¥æº\n\n"
    for j, chunk in enumerate(evidence_chunks):
        evidence_md += f"**[{j+1}]:**\n"
        evidence_md += f"{chunk['text']}\n"
        evidence_md += f"æ¥æº: {chunk['source']}\n\n"
    evidence_placeholder.markdown(evidence_md)

    # ç¬¬5æ­¥ï¼šè¯„ä¼°å£°æ˜
    verdict_placeholder.markdown("### âš–ï¸ æ­£åœ¨è¯„ä¼°å£°æ˜çœŸå®æ€§...")
    evaluation = fact_checker.evaluate_claim(information, user_input, evidence_chunks)

    verdict = evaluation["verdict"]
    if verdict.upper() == "TRUE":
        emoji = "âœ…"
        verdict_cn = "æ­£ç¡®"
    elif verdict.upper() == "FALSE":
        emoji = "âŒ"
        verdict_cn = "é”™è¯¯"
    elif verdict.upper() == "PARTIALLY TRUE":
        emoji = "âš ï¸"
        verdict_cn = "éƒ¨åˆ†æ­£ç¡®"
    else:
        emoji = "â“"
        verdict_cn = "æ— æ³•éªŒè¯"

    verdict_md = f"### {emoji} ç»“è®º: {verdict_cn}\n\n"
    verdict_md += f"### æ¨ç†è¿‡ç¨‹\n\n{evaluation['reasoning']}\n\n"
    verdict_placeholder.markdown(verdict_md)

    # æ•´åˆå®Œæ•´çš„å“åº”å†…å®¹ç”¨äºä¿å­˜åˆ°èŠå¤©å†å²
    full_response = f"""
### ğŸ” æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜

{claim}

---

{information}

---

{evidence_md}

---

{verdict_md}
"""
    st.session_state.messages.append({"role": "assistant", "content": full_response})